---
layout: post
title: "How do you think *brains* work?"
date: 2025-12-10
---

I worry “AI can think, actually” has become my “[AI isn’t bad for the environment, actually](https://andymasley.substack.com/p/individual-ai-use-is-not-bad-for)” and that I’m turning into a phil-mind Andy Masley.[^1] Except Andy Masley is just empirically correct, whereas I am making a philosophical point. So I could be wrong!

I hear a lot of objections to the idea that AI (specifically large language models like ChatGPT) can think. Some of them are quite interesting and important when you dig into them! But some are very frustrating when they are *used* as **instant, reflexive dismissals**. Stuff like:

> *AI is just repeating stuff it’s heard before.*
>
> *LLMs are just big piles of numbers doing stochastic token prediction.*
>
> *They’re just trained to mimic people.*
>
> *They can’t think, they can only spit out words.*

Readers, I beseech thee, in the bowels of Moloch: *how do you think brains work?*

Each of us appears to be governed by this fleshy mass of neurons sending binary[^2] chemical and electrical signals linked up to each other. Each neuron is extremely dumb. When it gets enough chemicals as input which opens enough little fleshy gates which lets in enough sodium ions, it shoots out an electrical impulse and releases more little chemicals. Each neuron “learns” new connections by dumb repetitive firing: it gets a little more sensitive to neurons that typically fire alongside it. As far as we can tell, everything that happens in here is stupid, mechanical, physics. And *somehow*, this big lump is bound up in something with emotions. Something that can reason, and laugh, and write poetry, and come up with new ideas, and all of that. Maybe it’s even bound up with a soul or some kind of nonreductive consciousness, powers strange and beyond our comprehension.

We have learned that this dumb fleshy mass sits at the nexus of all human intelligence. It is surprising, but we now know it to be true.

Why should it be that unthinkable that dumb masses of silicon and electrons could have some of that same stuff, work in some of the same ways? Why would this be limited to *brains?*

True, LLM architectures and brains are very different. Strikingly so! It would be quite surprising if they worked in *exactly* the same ways. Just as it would be quite surprising to meet an alien civilization which has the exact same biology, culture, and ways of reasoning that humans do. But it seems many people are open to the idea of real alien intelligence but *instinctively reject* artificial intelligence, on quite shoddy reasons that do not seem to point out genuine disanalogies.

LLMs are trained by next-token-prediction and gradient descent to generate outputs with a high reward score? Human brains were created by an evolutionary process which rewards them for making babies effectively!

LLMs are just math? Brains are just physics![^3]

LLMs mimic and recombine text they’ve seen? So does every human when *genuinely* learning to read, write, play music, do art, communicate, play…

I would be happy to talk disanalogies and differences between humans and LLMs all day. There are big differences, and maybe they make a difference in determining which is intelligent. But please, before you throw AI thinking out the window, consider:

- Could the same be said of [your 6th-grade brother](https://jacktlab.substack.com/p/if-ai-isnt-thinking-neither-is-your)?
- Could the same be said of intelligent aliens?
- Could the same be said of brains made of sodium pumps and retinal transduction and circuits trained by fire-together, wire-together?

If so, then I don’t think you’re genuinely distinguishing intelligence.

[^1]: Not the worst thing to be! :)
[^2]: Graded potentials do exist, but most action potentials are binary.
[^3]: Unless you believe souls can inhere in brains, to which I reply: why are you so confident souls *can’t* inhere in AI?
